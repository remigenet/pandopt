{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ff7bc1d-2fa8-4cdb-a97f-337a21520ba2",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8cdb40e-9b91-4d9d-b8a6-4b4d85dd31cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import inspect\n",
    "import types\n",
    "import numpy as np\n",
    "import numba as nb\n",
    "import pandas as pd\n",
    "import time\n",
    "import logging\n",
    "import functools\n",
    "import copy\n",
    "import sys\n",
    "from typing import Callable, Type, Dict, Tuple, Any\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e4c959-4902-4db8-a8c1-ec622650a0a8",
   "metadata": {},
   "source": [
    "## dev imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7e5a607-3a68-4f40-a264-450284074826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import astpretty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e72bf7-ba5d-4173-bd8f-a07c41338440",
   "metadata": {},
   "source": [
    "## Current state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80218408-85ac-4e99-88ac-477ceab50d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_callmap_function_ast(mapping: Dict[str, int]) -> ast.FunctionDef:\n",
    "    # Create the body of the callmap function\n",
    "    body = []\n",
    "    for key, value in mapping.items():\n",
    "        compare = ast.Compare(\n",
    "            left=ast.Name(id='x', ctx=ast.Load()),\n",
    "            ops=[ast.Eq()],\n",
    "            comparators=[ast.Constant(value=key)]\n",
    "        )\n",
    "        body.append(\n",
    "            ast.If(\n",
    "                test=compare,\n",
    "                body=[ast.Return(value=ast.Constant(value=value))],\n",
    "                orelse=[]\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # Add a default return statement\n",
    "    body.append(ast.Return(value=ast.Name(id='x', ctx=ast.Load())))\n",
    "\n",
    "    # Create the function definition\n",
    "    func_def = ast.FunctionDef(\n",
    "        name='callmap',\n",
    "        args=ast.arguments(\n",
    "            posonlyargs=[],\n",
    "            args=[ast.arg(arg='x')],\n",
    "            vararg=None,\n",
    "            kwonlyargs=[],\n",
    "            kw_defaults=[],\n",
    "            kwarg=None,\n",
    "            defaults=[]\n",
    "        ),\n",
    "        body=body,\n",
    "        decorator_list=[],\n",
    "        returns=None\n",
    "    )\n",
    "    return func_def\n",
    "\n",
    "class SubscriptReplacer(ast.NodeTransformer):\n",
    "    def __init__(self, arg_name):\n",
    "        self.arg_name = arg_name\n",
    "\n",
    "    def visit_Subscript(self, node):\n",
    "        if isinstance(node.value, ast.Name) and node.value.id == self.arg_name:\n",
    "            # Check for Python version compatibility\n",
    "            if sys.version_info >= (3, 9):\n",
    "                # Python 3.9 and later\n",
    "                old_slice = node.slice\n",
    "            else:\n",
    "                # Python 3.8 and earlier\n",
    "                old_slice = node.slice.value if isinstance(node.slice, ast.Index) else node.slice\n",
    "\n",
    "            # Wrap the subscript in a call to callmap\n",
    "            node.slice = ast.Call(\n",
    "                func=ast.Name(id='callmap', ctx=ast.Load()),\n",
    "                args=[old_slice],\n",
    "                keywords=[]\n",
    "            )\n",
    "        return self.generic_visit(node) \n",
    "\n",
    "def create_transformed_function_ast(original_func: Callable, mapping: Dict[str, int]) -> Tuple[ast.AST, ast.AST, ast.AST]:\n",
    "    # Parse the original function\n",
    "    original_tree = ast.parse(inspect.getsource(original_func))\n",
    "    arg_name = original_tree.body[0].args.args[0].arg\n",
    "    \n",
    "    # Rename the original function\n",
    "    original_tree.body[0].name = 'temporary'\n",
    "    \n",
    "    # Apply the AST transformation\n",
    "    replacer = SubscriptReplacer(arg_name)\n",
    "    original_tree = replacer.visit(original_tree)\n",
    "    ast.fix_missing_locations(original_tree)\n",
    "\n",
    "    # Replace dictionary accesses with callmap in the original function\n",
    "    # This would be similar to the code in SubscriptReplacer\n",
    "\n",
    "    # Create a new function that applies 'temporary' over an array\n",
    "    loop_base_func_str = f\"\"\"\n",
    "def {original_func.__qualname__}_loop(Z):\n",
    "    n = Z.shape[0]\n",
    "    res = np.zeros((n, 1))\n",
    "    for i in nb.prange(n):\n",
    "        res[i, 0] = temporary(Z[i, :])\n",
    "    return res\n",
    "    \"\"\"\n",
    "    vectorized_base_func_str = f\"\"\"\n",
    "def {original_func.__qualname__}_vectorized(Z):\n",
    "    return temporary(Z.T)\n",
    "    \"\"\"\n",
    "    loop_func_tree = ast.parse(loop_base_func_str)\n",
    "    vectorize_func_tree = ast.parse(vectorized_base_func_str)\n",
    "\n",
    "    return original_tree, loop_func_tree, vectorize_func_tree\n",
    "\n",
    "def numba_decorate(func_tree: ast.AST, nopython: bool = True, nogil: bool = True, parallel: bool = True) -> ast.AST:\n",
    "    # # Add Numba JIT decorator\n",
    "    nb_compyled_func_tree = copy.deepcopy(ast.fix_missing_locations(func_tree))\n",
    "    numba_decorator = ast.Call(\n",
    "        func=ast.Attribute(value=ast.Name(id='nb', ctx=ast.Load()), attr='jit', ctx=ast.Load()),\n",
    "        args=[],\n",
    "        keywords=[\n",
    "            ast.keyword(arg='nopython', value=ast.Constant(value=nopython)),\n",
    "            ast.keyword(arg='nogil', value=ast.Constant(value=nogil)),\n",
    "            ast.keyword(arg='parallel', value=ast.Constant(value=parallel))\n",
    "        ]\n",
    "    )\n",
    "    nb_compyled_func_tree.body[0].decorator_list.append(numba_decorator)\n",
    "    nb_compyled_func_tree.body[0].name += '_nb_compyled'\n",
    "    return ast.fix_missing_locations(nb_compyled_func_tree)\n",
    "\n",
    "def encapulate(wrap_tree: ast.AST, callmap_tree: ast.AST, original_tree: ast.AST) -> ast.AST:\n",
    "    wrap_tree.body[0].body.insert(0, callmap_tree.body[0])\n",
    "    wrap_tree.body[0].body.insert(1, original_tree.body[0])\n",
    "    return ast.fix_missing_locations(wrap_tree)\n",
    "\n",
    "def compile_tree(built_func_tree: ast.AST, exec_globals: Dict[str, Any], qualname: str, build_qualifier: str) -> Dict:\n",
    "    try:\n",
    "        exec(compile(built_func_tree, filename=\"<ast>\", mode=\"exec\"), exec_globals)\n",
    "        return {build_qualifier: exec_globals[qualname + build_qualifier]}\n",
    "    except Exception as e:\n",
    "        logger.warning(e)\n",
    "    return {}\n",
    "\n",
    "def _prepare_funcs(original_func: ast.AST, mapping: Dict[str, int]) -> Dict[str, Callable]:\n",
    "    exec_globals = globals().copy()\n",
    "    exec_globals.update({'np': np, 'nb': nb})\n",
    "    callmap_func_ast = create_callmap_function_ast(mapping)\n",
    "    callmap_func_tree = ast.fix_missing_locations(ast.Module(body=[callmap_func_ast], type_ignores=[]))\n",
    "    original_tree, loop_func_tree, vectorize_func_tree = create_transformed_function_ast(original_func, mapping)\n",
    "\n",
    "    loop_func_tree = encapulate(loop_func_tree, callmap_func_tree, original_tree)\n",
    "    vectorize_func_tree = encapulate(vectorize_func_tree, callmap_func_tree, original_tree)\n",
    "    \n",
    "    available_funcs = {}\n",
    "    available_funcs.update(compile_tree(vectorize_func_tree, exec_globals, original_func.__qualname__, '_vectorized'))\n",
    "    available_funcs.update(compile_tree(loop_func_tree, exec_globals, original_func.__qualname__, '_loop'))\n",
    "    \n",
    "    nb_compyled_loop_func_tree = numba_decorate(loop_func_tree)\n",
    "    nb_compyled_vectorize_func_tree = numba_decorate(vectorize_func_tree)\n",
    "\n",
    "    available_funcs.update(compile_tree(nb_compyled_vectorize_func_tree, exec_globals, original_func.__qualname__, '_vectorized_nb_compyled'))\n",
    "    available_funcs.update(compile_tree(nb_compyled_loop_func_tree, exec_globals, original_func.__qualname__, '_loop_nb_compyled'))\n",
    "\n",
    "    return available_funcs\n",
    "\n",
    "def make_class_decorator(function_decorator: Callable) -> Callable:\n",
    "    \"\"\"\n",
    "    Creates a class decorator from a given function decorator.\n",
    "\n",
    "    Args:\n",
    "        function_decorator (Callable): A function decorator to be applied to class methods.\n",
    "\n",
    "    Returns:\n",
    "        Callable: A class decorator.\n",
    "    \"\"\"\n",
    "    @functools.wraps(function_decorator)\n",
    "    def class_decorator(cls: Type) -> Type:\n",
    "        \"\"\"\n",
    "        The class decorator generated from the function decorator.\n",
    "\n",
    "        Args:\n",
    "            cls (Type): The class to which the decorator is applied.\n",
    "\n",
    "        Returns:\n",
    "            Type: The decorated class.\n",
    "        \"\"\"\n",
    "        for attr_name, attr_value in cls.__bases__[0].__dict__.items():\n",
    "            if callable(attr_value) and not attr_name.startswith('_') and attr_name not in cls.__dict__:\n",
    "                setattr(cls, attr_name, function_decorator(attr_value))\n",
    "        for attr_name, attr_value in cls.__dict__.items():\n",
    "             if callable(attr_value) and not attr_name.startswith('_'):\n",
    "                setattr(cls, attr_name, function_decorator(attr_value))\n",
    "        return cls\n",
    "    return class_decorator\n",
    "\n",
    "def autowrap_pandas_return(fn: Callable) -> Callable:\n",
    "    \"\"\"\n",
    "    Decorator to add validation and error handling to class methods.\n",
    "\n",
    "    Args:\n",
    "        fn (Callable): The original method of the class.\n",
    "\n",
    "    Returns:\n",
    "        Callable: The decorated method with added validation and error handling.\n",
    "    \"\"\"\n",
    "    @functools.wraps(fn)\n",
    "    def wrapper(self, *args, **kwargs):\n",
    "        if self._outside_call:\n",
    "            self._outside_call = False\n",
    "            res = fn(self, *args, **kwargs)\n",
    "            if isinstance(res, pd.DataFrame):\n",
    "                res = pandopt(res)\n",
    "            self._outside_call = True\n",
    "            return res\n",
    "        return fn(self, *args, **kwargs)\n",
    "    return wrapper\n",
    "\n",
    "@make_class_decorator(autowrap_pandas_return)\n",
    "class pandopt(pd.DataFrame):\n",
    "    _compiled_func = None\n",
    "    _outside_call = True\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self._compiled_func = {}\n",
    "\n",
    "    @property\n",
    "    def __name__(self):\n",
    "        return functools.reduce(lambda x, y: x + y, self.name_to_index.keys())\n",
    "\n",
    "    @property\n",
    "    def colname_to_colnum(self):\n",
    "        return {k: i for i, k in enumerate(self.columns)}\n",
    "\n",
    "    @property\n",
    "    def rowname_to_rownum(self):\n",
    "        return {k: i for i, k in enumerate(self.index)}\n",
    "    \n",
    "    def _compiled_qualifier(self, func_qualifier, mapper):\n",
    "        return hash(functools.reduce(lambda x, y: f'{x}&{y}', mapper) + func_qualifier)\n",
    "\n",
    "    def apply(self, func, axis = 0, *args, pandas_fallback = False, **kwargs):\n",
    "        if pandas_fallback: \n",
    "            logger.warning(f'{__class__} finish in pandas fallback for func {func}')\n",
    "            return super().apply(func, axis = 0, *args, **kwargs)\n",
    "        if args or kwargs:\n",
    "            logger.warning(f'{__class__} apply only supports func and axis arguments, using default pandas apply')\n",
    "            return super().apply(func, axis = 0, *args, **kwargs)\n",
    "        return pandopt((self._compiled_func.get((name:=self._compiled_qualifier(func_qualifier = func.__qualname__, mapper=(mapper:=self.colname_to_colnum if axis else self.rowname_to_rownum)))) or self._build_apply_versions(func, mapper, name))(self.to_numpy() if axis else self.to_numpy().T), index = self.index if axis else self.columns)\n",
    "\n",
    "    def _with_fallback_wrap(self, apply_func_dict):\n",
    "        def _with_protects(*args, **kwargs):\n",
    "            for key in ('_vectorized_nb_compyled', '_loop_compyled', '_vectorized', '_loop'):\n",
    "                if key not in apply_func_dict:\n",
    "                    continue\n",
    "                try:\n",
    "                    return apply_func_dict[key](*args, **kwargs)\n",
    "                except:\n",
    "                    apply_func_dict.pop(key)\n",
    "            return self.apply(*args, pandas_fallback = True, **kwargs)\n",
    "        return _with_protects\n",
    "    \n",
    "    def _build_apply_versions(self, func, map, name):\n",
    "        self._compiled_func[name] = self._with_fallback_wrap(_prepare_funcs(func, map))\n",
    "        return self._compiled_func[name]\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "975a4086-b916-4936-aa70-7ae890b478e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @nb.jit(fastmath=True, forceinline=True, looplift=True, inline='always', target_backend='host', no_cfunc_wrapper=True, no_rewrites=True,nopython=True, nogil=True, parallel = True)\n",
    "def mean(x):\n",
    "    res=x.shape[1]\n",
    "    for k in nb.prange(x.shape[1]):\n",
    "        res[k]= np.mean(x[:,k])\n",
    "    return res\n",
    "\n",
    "def mmean(x):\n",
    "    return functools.reduce(lambda k, z: k + z, x)/len(x)\n",
    "\n",
    "df=pd.DataFrame(data=np.random.randn(10000,4), columns = ['A', 'B', 'C', 'D']).astype(np.float32)\n",
    "dfx = pandopt(df)\n",
    "# %timeit dfx.mean()\n",
    "# %timeit df.mean()\n",
    "# %timeit np.mean(dfx.to_numpy(), axis=0)\n",
    "# %timeit mean(dfx.to_numpy())\n",
    "# %timeit dfx.apply(mmean)\n",
    "# %timeit dfx.apply(mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "140a93fb-1511-4552-a583-389fae6e5e63",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m np\u001b[38;5;241m.\u001b[39mmean(dfx\u001b[38;5;241m.\u001b[39mto_numpy(), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m),  \u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdfx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, df\u001b[38;5;241m.\u001b[39mmean()\n",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m, in \u001b[0;36mmean\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      3\u001b[0m res\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m nb\u001b[38;5;241m.\u001b[39mprange(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]):\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mres\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(x[:,k])\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "np.mean(dfx.to_numpy(), axis=0),  mean(dfx.to_numpy()), df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9cb54a-77cf-47c7-9a05-17ee9ade8379",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit np.mean(dfx.to_numpy())\n",
    "%timeit mean(dfx.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b870696-ffd1-41b5-afdc-dadf98640fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.jit(fastmath=True, forceinline=True, looplift=True, inline='always', target_backend='host', no_cfunc_wrapper=True,nopython=True, nogil=True, parallel = True)\n",
    "def var1(x):\n",
    "    K=x.shape\n",
    "    print(x)\n",
    "    res = np.zeros((K,1))\n",
    "    for k in nb.prange():\n",
    "        res[k,0] = np.var(x[:,k])\n",
    "    return res\n",
    "\n",
    "@nb.jit(fastmath=True, forceinline=True, looplift=True, inline='always', target_backend='host', no_cfunc_wrapper=True, no_rewrites=True ,nopython=True, nogil=True, parallel = True)\n",
    "def var2(x):\n",
    "    m = np.sum(x, axis=0)/x.shape[0]\n",
    "    return (m**2 - m)\n",
    "    \n",
    "var2(df.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40693ed7-28d0-40ee-b22a-a8da6a18f94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=0\n",
    "def test(x):\n",
    "    global a\n",
    "    a+=1\n",
    "    return np.mean(x)\n",
    "\n",
    "test(df.rolling(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a586757-f349-4bd5-9953-7bdcb1d754ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return np.mean(x)\n",
    "\n",
    "def f2(x):\n",
    "    return functools.reduce(lambda k, z: k + z, x)/len(x)\n",
    "\n",
    "%timeit df.mean(axis=1)\n",
    "%timeit df.apply(np.mean, axis=1)\n",
    "%timeit dfx.apply(f, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209057d1-131f-4919-bc83-491260f90a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mymean(x):\n",
    "    return functools.reduce(lambda k, z: k + z, x)/len(x)\n",
    "\n",
    "def somemean(x):\n",
    "    return sum(x)/len(x)\n",
    "\n",
    "df=pd.DataFrame(data=np.random.randn(1000000,4), columns = ['A', 'B', 'C', 'D']).astype(np.float32)\n",
    "dfx = pandopt(df)\n",
    "\n",
    "\n",
    "%time df.mean(axis=1)\n",
    "%time df.apply(np.mean, axis=1)\n",
    "%time dfx.apply(mymean, axis=1)\n",
    "%time dfx.apply(somemean, axis=1)\n",
    "\n",
    "print(df.mean(axis=1))\n",
    "print(df.apply(np.mean, axis=1))\n",
    "print(dfx.apply(mymean, axis=1))\n",
    "print(dfx.apply(somemean, axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5748555b-0473-4bfa-9efc-2e861919d092",
   "metadata": {},
   "outputs": [],
   "source": [
    "[attr for attr in dir(df) if hasattr(np, attr) and \"__\" not in attr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0cff6e-a81c-4632-8469-b77885526dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abde2e92-7f7d-4d36-b6a2-c2046cb010fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7252d459-e2e2-4b2f-9d45-db3109a5b3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.mean(sliding_window_view(df.to_numpy(), 5, axis=0), axis=2)).values - 1).abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc595e8-bc46-4966-8acb-57c311e5ca85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@nb.jit(nopython=True, nogil=True, parallel=True)\n",
    "def cdmtest_func(Z):\n",
    "    def callmap(x):\n",
    "        if x == 'A':\n",
    "            return 0\n",
    "        elif x == 'B':\n",
    "            return 1\n",
    "        elif x == 'C':\n",
    "            return 2\n",
    "        elif x == 'D':\n",
    "            return 3\n",
    "        return x\n",
    "    def tmporary(x):\n",
    "        return np.kurt(x)\n",
    "    n = Z.shape[0]\n",
    "    res = np.zeros((n, 1))\n",
    "    for i in nb.prange(5, n):\n",
    "        res[i,0] = np.var(Z[i-5:i,:])\n",
    "    return res\n",
    "\n",
    "\n",
    "def mymean(x):\n",
    "    return functools.reduce(lambda k, z: k + z, x)/len(x)\n",
    "\n",
    "\n",
    "df=pd.DataFrame(data=np.random.randn(10000,4), columns = ['A', 'B', 'C', 'D']).astype(np.float32)\n",
    "dfx = pandopt(df)\n",
    "\n",
    "%time cdmtest_func(df.to_numpy())\n",
    "\n",
    "%time df.rolling(5).var()\n",
    "%time df.rolling(5).apply(np.var)\n",
    "%time dfx.rolling(5).apply(mymean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc3413d-f8ec-46bb-9171-0b445186522e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_func(z):\n",
    "    x = (z['A']+z['B'])\n",
    "    x = z['B']*z['D']\n",
    "    return x / z['B']\n",
    "\n",
    "@nb.jit(nopython=True, nogil=True, parallel=True, cache=True)\n",
    "def test_funcv(z):\n",
    "    x = (z[:,0]+z[:,1])\n",
    "    x = z[:,0]*z[:,3]\n",
    "    return x / z[:,1]\n",
    "\n",
    "@nb.jit(nopython=True, nogil=True, cache=True)\n",
    "def test_funcd(z):\n",
    "    x = (z[0]+z[1])\n",
    "    x = z[0]*z[3]\n",
    "    return x / z[1]\n",
    "\n",
    "@nb.jit(nopython=True, nogil=True, parallel=True, cache=True)\n",
    "def test_funcdd(z):\n",
    "    for i in nb.prange(len(z)):\n",
    "        z[i,0]=test_funcd(z[i])\n",
    "    return z[:,0]\n",
    "    \n",
    "def rowtest_func(z):\n",
    "    x = (z['A']+z['B'])\n",
    "    if x > 0:\n",
    "        return z['B']*z['D']\n",
    "    return x / z['B']\n",
    "\n",
    "@nb.jit(nopython=True, nogil=True, cache=True)\n",
    "def rowtest_funcdi(z):\n",
    "    x = (z[0]+z[1])\n",
    "    if x > 0:\n",
    "        return z[0]*z[3]\n",
    "    return x / z[1]\n",
    "\n",
    "@nb.jit(nopython=True, nogil=True, parallel=True)\n",
    "def rowtest_funcddo(z):\n",
    "    n = len(z)\n",
    "    result = np.zeros((n,1), dtype=np.float32)\n",
    "    for i in nb.prange(n):\n",
    "        result[i,0] = rowtest_funcdi(z[i,:])\n",
    "    return result\n",
    "\n",
    "@nb.jit(nopython=True, nogil=True, parallel=True)\n",
    "def rowtest_funcdd(z):\n",
    "    n = len(z)\n",
    "    result = np.zeros((n,1), dtype=np.float32)\n",
    "    for i in nb.prange(n):\n",
    "        x = (z[i, 0]+z[i, 1])\n",
    "        if x > 0:\n",
    "            result[i,0] = z[i, 0]*z[i, 3]\n",
    "            continue\n",
    "        result[i,0] = z[i,0]\n",
    "        continue\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "@nb.jit(nopython=True, nogil=True, parallel=True)\n",
    "def rowtest_funcdv(z):\n",
    "    x = (z[:,0]+z[:,1])\n",
    "    return ((x > 0) * z[:,0]*z[:,3]) + ((x < 0) * x / z[:,1])\n",
    "\n",
    "\n",
    "df=pd.DataFrame(data=np.random.randn(10**3,4), columns = ['A', 'B', 'C', 'D']).astype(np.float32)\n",
    "arr=df.astype(np.float32).to_numpy()\n",
    "print(df.apply(rowtest_func, axis=1))\n",
    "print(rowtest_funcdd(arr.copy()), rowtest_funcdd(arr.copy()).shape, np.sum(rowtest_funcdd(arr.copy())))\n",
    "print(rowtest_funcdv(arr.copy()), rowtest_funcdv(arr.copy()).shape, np.sum(rowtest_funcdv(arr.copy())))\n",
    "\n",
    "print(df.apply(test_func, axis=1))\n",
    "print(test_funcdd(arr.copy()), test_funcdd(arr.copy()).shape, np.sum(test_funcdd(arr.copy())))\n",
    "print(test_funcv(arr.copy()), test_funcv(arr.copy()).shape, np.sum(test_funcv(arr.copy())))\n",
    "\n",
    "df.rolling(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66db4807-087b-4cf4-abde-b84b4675ab9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit var1(df.to_numpy())\n",
    "%timeit var2(df.to_numpy())\n",
    "%timeit np.var(df.to_numpy(), axis=0)\n",
    "%timeit df.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00df8066-95b3-4075-a34e-b8a3fd10caaa",
   "metadata": {},
   "source": [
    "## Func compilation / live modification performance test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e636b3b-c151-44ca-b8ec-0d6972c9b305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "def simple_start(z):\n",
    "    x = (z['A'] + z['B']) / z['C']\n",
    "    x += z['B'] * z['D']\n",
    "    return x / z['B']\n",
    "\n",
    "def harder_func(z):\n",
    "    x = (z['A'] + z['B']) / z['C']\n",
    "    if x > 0:\n",
    "        return x / z['B']\n",
    "    x += z['B'] * z['D']\n",
    "    return x * z['B']\n",
    "\n",
    "def harder2_func(z):\n",
    "    x = (z['A'] + z['B']) / z['C']\n",
    "    if (k:=z['A']-z['C']) > (j:=z['B']/z['D']):\n",
    "        return x / k\n",
    "    x *= j\n",
    "    return x - k if k > z['C'] else x + k\n",
    "\n",
    "def harder3_func(z):\n",
    "    g=lambda a, b: a if abs(a) > abs(b) else - 2 * (b**(-a))\n",
    "    x = (z['A'] + z['B']) / z['C']\n",
    "    if (k:=z['A']-z['C']) > (j:=g(z['B'],z['D'])):\n",
    "        return j / k\n",
    "    x *= j\n",
    "    return x - k if k > z['C'] else x + k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865613bc-a940-4f1f-b219-b3d29ac0f14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=pd.DataFrame(data=np.random.randn(100000,4), columns = ['A', 'B', 'C', 'D']).astype(np.float32)\n",
    "mapping = {k: i for i, k in enumerate(df.columns)}\n",
    "\n",
    "for func_test in [simple_start, harder_func, harder2_func, harder3_func]:\n",
    "    print('Testing ', func_test.__name__)\n",
    "    prepared_funcs = _prepare_funcs(func_test, mapping)\n",
    "    try:\n",
    "        print('df.apply(f, axis=1):', end=' ')\n",
    "        %timeit df.apply(func_test, axis=1)\n",
    "        print('checksum: ', np.sum(df.apply(func_test, axis=1)))\n",
    "    except Exception as e:\n",
    "        print('df.apply(f, axis=1) FAILED : ', e)\n",
    "    try:\n",
    "        print('test_func(df):', end=' ')\n",
    "        %timeit func_test(df)\n",
    "        print('checksum: ', np.sum(func_test(df)))\n",
    "    except Exception as e:\n",
    "        print('test_func(df) FAILED : ', e)\n",
    "    try:\n",
    "        print('_loop(df):', end=' ')\n",
    "        %timeit prepared_funcs['_loop'](df.to_numpy())\n",
    "        print('checksum: ', np.sum(prepared_funcs['_loop'](df.to_numpy())))\n",
    "    except Exception as e:\n",
    "        print('safe_func(df) FAILED : ', e)\n",
    "    try:\n",
    "        print('_vectorize(df):', end=' ')\n",
    "        %timeit prepared_funcs['_vectorize'](df.to_numpy())\n",
    "        print('checksum: ', np.sum(prepared_funcs['_vectorize'](df.to_numpy().T)))\n",
    "    except Exception as e:\n",
    "        print('vectorized_func(df) FAILED : ', e)\n",
    "    try:\n",
    "        print('_loop_nb_compyled(df):', end=' ')\n",
    "        %timeit prepared_funcs['_loop_nb_compyled'](df.to_numpy())\n",
    "        print('checksum: ', np.sum(prepared_funcs['_loop_nb_compyled'](df.to_numpy())))\n",
    "    except Exception as e:\n",
    "        print('opt_func(df) FAILED : ', e)\n",
    "    try:\n",
    "        print('_vectorized_nb_compyled(df):', end=' ')\n",
    "        %timeit prepared_funcs['_vectorized_nb_compyled'](df.to_numpy())\n",
    "        print('checksum: ', np.sum(prepared_funcs['_vectorized_nb_compyled'](df.to_numpy().T)))\n",
    "    except Exception as e:\n",
    "        print('opt_func(df) FAILED : ', e)\n",
    "    print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef7fc68-a61e-4a53-953a-33f349cc7874",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.lib.stride_tricks import as_strided, sliding_window_view\n",
    "def aid(x):\n",
    "    # This function returns the memory\n",
    "    # block address of an array.\n",
    "    return x.__array_interface__['data'][0]\n",
    "\n",
    "n = 5\n",
    "k = 2\n",
    "a = np.random.randn(10,3)\n",
    "ax = aid(a)\n",
    "\n",
    "aid(a), aid(as_strided(a, (k, n), (8, 8)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26c493a-6ea7-4213-9497-2b575966aa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data=np.random.randn(100,4), columns = ['A', 'B', 'C', 'D']).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f35d32-21e9-4b8e-8c38-b2a278c85e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(roll(df.to_numpy(),5), axis=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b18e02-b1ca-4e5c-bea8-012592b58acd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44a433b-eeb7-4670-b2e9-019badc21961",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rolling(5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e8553e-8319-4728-9981-982896b2de1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.rolling(5).mean().dropna() / "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59a51b7-4c42-4acc-83e5-8f67b338eda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rolling(5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4893ac1d-ed22-40a6-9108-fe118c792ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.mean(roll(df.to_numpy(),5), axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308cf8f7-448d-4e93-ae53-3b6709aa41c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "roll(df.to_numpy(),5)[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f39a5f-2faf-4d09-a5b9-0e0507bdf310",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rolling(5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f94482-d69a-44f4-b425-7f36dc6d6a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "as_strided(a, (k, n - k + 1),\n",
    "                      (x.itemsize, x.itemsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ceda339-8f5a-4ce2-a9ce-22a77a9b6300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4145435-277e-4d98-9ded-99cf0acd1a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "as_strided(a, a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4986404-20ab-4c0f-a0f3-0be4d4c60808",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data=np.random.randn(1000000,4), columns = ['A', 'B', 'C', 'D']).astype(np.float32)\n",
    "dfx = pandopt(df)\n",
    "dfx.apply(simple_start, axis=1)\n",
    "\n",
    "for func_test in [simple_start, harder_func, harder2_func, harder3_func]:\n",
    "    print('Testing ', func_test.__name__)\n",
    "\n",
    "    default = df.apply(func_test, axis=1)\n",
    "    new = dfx.apply(func_test, axis=1)\n",
    "\n",
    "    if sum(default - new)\n",
    "\n",
    "    %timeit df.apply(func_test, axis=1)\n",
    "\n",
    "    %timeit dfx.apply(func_test, axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8640e71b-2f44-4390-9876-6d569710164c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_start(z):\n",
    "    x = (z['A'] + z['B']) / z['C']\n",
    "    x += z['B'] * z['D']\n",
    "    return x / z['B']\n",
    "\n",
    "\n",
    "df=pd.DataFrame(data=np.random.randn(1000000,4), columns = ['A', 'B', 'C', 'D']).astype(np.float32)\n",
    "dfx = pandopt(df)\n",
    "\n",
    "%time df.apply(simple_start, axis=1)\n",
    "\n",
    "%time dfx.apply(simple_start, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c9dff9-910c-4f00-be63-26c1bf2464d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_start(z):\n",
    "    x = (z['A'] + z['B']) / z['C']\n",
    "    x += z['B'] * z['D']\n",
    "    return x / z['B']\n",
    "\n",
    "df=pd.DataFrame(data=np.random.randn(10000000,4), columns = ['A', 'B', 'C', 'D']).astype(np.float32)\n",
    "dfx = pandopt(df)\n",
    "\n",
    "%time df.apply(simple_start, axis=1)\n",
    "\n",
    "%time dfx.apply(simple_start, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18e97ca-82b9-438a-ba4e-2afd35f07d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data=np.random.randn(1000000,4), columns = ['A', 'B', 'C', 'D']).astype(np.float32)\n",
    "dfx = pandopt(df)\n",
    "\n",
    "%time df.rolling(10).var()\n",
    "%time pd.DataFrame(np.var(sliding_window_view(df.to_numpy(), 10, axis=0), axis=2), columns=df.columns, index=df.index[9:])\n",
    "#%time dfx.apply(simple_start, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0879de-2aee-43e8-b354-16b2d0af1daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_callmap_function_ast(mapping: Dict[str, int]) -> ast.FunctionDef:\n",
    "    # Create the body of the callmap function\n",
    "    body = []\n",
    "    for key, value in mapping.items():\n",
    "        compare = ast.Compare(\n",
    "            left=ast.Name(id='x', ctx=ast.Load()),\n",
    "            ops=[ast.Eq()],\n",
    "            comparators=[ast.Constant(value=key)]\n",
    "        )\n",
    "        body.append(\n",
    "            ast.If(\n",
    "                test=compare,\n",
    "                body=[ast.Return(value=ast.Constant(value=value))],\n",
    "                orelse=[]\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # Add a default return statement\n",
    "    body.append(ast.Return(value=ast.Name(id='x', ctx=ast.Load())))\n",
    "\n",
    "    # Create the function definition\n",
    "    func_def = ast.FunctionDef(\n",
    "        name='callmap',\n",
    "        args=ast.arguments(\n",
    "            posonlyargs=[],\n",
    "            args=[ast.arg(arg='x')],\n",
    "            vararg=None,\n",
    "            kwonlyargs=[],\n",
    "            kw_defaults=[],\n",
    "            kwarg=None,\n",
    "            defaults=[]\n",
    "        ),\n",
    "        body=body,\n",
    "        decorator_list=[],\n",
    "        returns=None\n",
    "    )\n",
    "    return func_def\n",
    "\n",
    "class SubscriptReplacer(ast.NodeTransformer):\n",
    "    def __init__(self, arg_name):\n",
    "        self.arg_name = arg_name\n",
    "\n",
    "    def visit_Subscript(self, node):\n",
    "        if isinstance(node.value, ast.Name) and node.value.id == self.arg_name:\n",
    "            # Check for Python version compatibility\n",
    "            if sys.version_info >= (3, 9):\n",
    "                # Python 3.9 and later\n",
    "                old_slice = node.slice\n",
    "            else:\n",
    "                # Python 3.8 and earlier\n",
    "                old_slice = node.slice.value if isinstance(node.slice, ast.Index) else node.slice\n",
    "\n",
    "            # Wrap the subscript in a call to callmap\n",
    "            node.slice = ast.Call(\n",
    "                func=ast.Name(id='callmap', ctx=ast.Load()),\n",
    "                args=[old_slice],\n",
    "                keywords=[]\n",
    "            )\n",
    "        return self.generic_visit(node) \n",
    "\n",
    "def create_transformed_function_ast(original_func: Callable, mapping: Dict[str, int]) -> Tuple[ast.AST, ast.AST, ast.AST]:\n",
    "    # Parse the original function\n",
    "    original_tree = ast.parse(inspect.getsource(original_func))\n",
    "    arg_name = original_tree.body[0].args.args[0].arg\n",
    "    \n",
    "    # Rename the original function\n",
    "    original_tree.body[0].name = 'temporary'\n",
    "    \n",
    "    # Apply the AST transformation\n",
    "    replacer = SubscriptReplacer(arg_name)\n",
    "    original_tree = replacer.visit(original_tree)\n",
    "    ast.fix_missing_locations(original_tree)\n",
    "\n",
    "    # Replace dictionary accesses with callmap in the original function\n",
    "    # This would be similar to the code in SubscriptReplacer\n",
    "\n",
    "    # Create a new function that applies 'temporary' over an array\n",
    "    loop_base_func_str = f\"\"\"\n",
    "def {original_func.__qualname__}_loop(Z):\n",
    "    n = Z.shape[0]\n",
    "    res = np.zeros((n, 1))\n",
    "    for i in nb.prange(n):\n",
    "        res[i, 0] = temporary(Z[i, :])\n",
    "    return res\n",
    "    \"\"\"\n",
    "    vectorized_base_func_str = f\"\"\"\n",
    "def {original_func.__qualname__}_vectorized(Z):\n",
    "    return temporary(Z.T)\n",
    "    \"\"\"\n",
    "    loop_func_tree = ast.parse(loop_base_func_str)\n",
    "    vectorize_func_tree = ast.parse(vectorized_base_func_str)\n",
    "\n",
    "    return original_tree, loop_func_tree, vectorize_func_tree\n",
    "\n",
    "def numba_decorate(func_tree: ast.AST, nopython: bool = True, nogil: bool = True, parallel: bool = True) -> ast.AST:\n",
    "    # # Add Numba JIT decorator\n",
    "    nb_compyled_func_tree = copy.deepcopy(ast.fix_missing_locations(func_tree))\n",
    "    numba_decorator = ast.Call(\n",
    "        func=ast.Attribute(value=ast.Name(id='nb', ctx=ast.Load()), attr='jit', ctx=ast.Load()),\n",
    "        args=[],\n",
    "        keywords=[\n",
    "            ast.keyword(arg='nopython', value=ast.Constant(value=nopython)),\n",
    "            ast.keyword(arg='nogil', value=ast.Constant(value=nogil)),\n",
    "            ast.keyword(arg='parallel', value=ast.Constant(value=parallel))\n",
    "        ]\n",
    "    )\n",
    "    nb_compyled_func_tree.body[0].decorator_list.append(numba_decorator)\n",
    "    nb_compyled_func_tree.body[0].name += '_nb_compyled'\n",
    "    return ast.fix_missing_locations(nb_compyled_func_tree)\n",
    "\n",
    "def encapulate(wrap_tree: ast.AST, callmap_tree: ast.AST, original_tree: ast.AST) -> ast.AST:\n",
    "    wrap_tree.body[0].body.insert(0, callmap_tree.body[0])\n",
    "    wrap_tree.body[0].body.insert(1, original_tree.body[0])\n",
    "    return ast.fix_missing_locations(wrap_tree)\n",
    "\n",
    "def compile_tree(built_func_tree: ast.AST, exec_globals: Dict[str, Any], qualname: str, build_qualifier: str) -> Dict:\n",
    "    try:\n",
    "        exec(compile(built_func_tree, filename=\"<ast>\", mode=\"exec\"), exec_globals)\n",
    "        return {build_qualifier: exec_globals[qualname + build_qualifier]}\n",
    "    except Exception as e:\n",
    "        logger.warning(e)\n",
    "    return {}\n",
    "\n",
    "def _prepare_funcs(original_func: ast.AST, mapping: Dict[str, int]) -> Dict[str, Callable]:\n",
    "    exec_globals = globals().copy()\n",
    "    exec_globals.update({'np': np, 'nb': nb})\n",
    "    callmap_func_ast = create_callmap_function_ast(mapping)\n",
    "    callmap_func_tree = ast.fix_missing_locations(ast.Module(body=[callmap_func_ast], type_ignores=[]))\n",
    "    original_tree, loop_func_tree, vectorize_func_tree = create_transformed_function_ast(original_func, mapping)\n",
    "\n",
    "    loop_func_tree = encapulate(loop_func_tree, callmap_func_tree, original_tree)\n",
    "    vectorize_func_tree = encapulate(vectorize_func_tree, callmap_func_tree, original_tree)\n",
    "    \n",
    "    available_funcs = {}\n",
    "    available_funcs.update(compile_tree(vectorize_func_tree, exec_globals, original_func.__qualname__, '_vectorized'))\n",
    "    available_funcs.update(compile_tree(loop_func_tree, exec_globals, original_func.__qualname__, '_loop'))\n",
    "    \n",
    "    nb_compyled_loop_func_tree = numba_decorate(loop_func_tree)\n",
    "    nb_compyled_vectorize_func_tree = numba_decorate(vectorize_func_tree)\n",
    "\n",
    "    available_funcs.update(compile_tree(nb_compyled_vectorize_func_tree, exec_globals, original_func.__qualname__, '_vectorized_nb_compyled'))\n",
    "    available_funcs.update(compile_tree(nb_compyled_loop_func_tree, exec_globals, original_func.__qualname__, '_loop_nb_compyled'))\n",
    "\n",
    "    return available_funcs\n",
    "\n",
    "def make_class_decorator(function_decorator: Callable) -> Callable:\n",
    "    \"\"\"\n",
    "    Creates a class decorator from a given function decorator.\n",
    "\n",
    "    Args:\n",
    "        function_decorator (Callable): A function decorator to be applied to class methods.\n",
    "\n",
    "    Returns:\n",
    "        Callable: A class decorator.\n",
    "    \"\"\"\n",
    "    @functools.wraps(function_decorator)\n",
    "    def class_decorator(cls: Type) -> Type:\n",
    "        \"\"\"\n",
    "        The class decorator generated from the function decorator.\n",
    "\n",
    "        Args:\n",
    "            cls (Type): The class to which the decorator is applied.\n",
    "\n",
    "        Returns:\n",
    "            Type: The decorated class.\n",
    "        \"\"\"\n",
    "        for attr_name, attr_value in cls.__bases__[0].__dict__.items():\n",
    "            if callable(attr_value) and not attr_name.startswith('_') and attr_name not in cls.__dict__:\n",
    "                setattr(cls, attr_name, function_decorator(attr_value))\n",
    "        for attr_name, attr_value in cls.__dict__.items():\n",
    "             if callable(attr_value) and not attr_name.startswith('_'):\n",
    "                setattr(cls, attr_name, function_decorator(attr_value))\n",
    "        return cls\n",
    "    return class_decorator\n",
    "\n",
    "def autowrap_pandas_return(fn: Callable) -> Callable:\n",
    "    \"\"\"\n",
    "    Decorator to add validation and error handling to class methods.\n",
    "\n",
    "    Args:\n",
    "        fn (Callable): The original method of the class.\n",
    "\n",
    "    Returns:\n",
    "        Callable: The decorated method with added validation and error handling.\n",
    "    \"\"\"\n",
    "    @functools.wraps(fn)\n",
    "    def wrapper(self, *args, **kwargs):\n",
    "        if self._outside_call:\n",
    "            self._outside_call = False\n",
    "            res = fn(self, *args, **kwargs)\n",
    "            if isinstance(res, pd.DataFrame):\n",
    "                res = pandopt(res)\n",
    "            self._outside_call = True\n",
    "            return res\n",
    "        return fn(self, *args, **kwargs)\n",
    "    return wrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7366b5da-e96c-449a-97d3-159aaa435e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@make_class_decorator(autowrap_pandas_return)\n",
    "class pandopt(pd.DataFrame):\n",
    "    _compiled_func = None\n",
    "    _outside_call = True\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self._compiled_func = {}\n",
    "\n",
    "    @property\n",
    "    def __name__(self):\n",
    "        return functools.reduce(lambda x, y: x + y, self.name_to_index.keys())\n",
    "\n",
    "    @property\n",
    "    def colname_to_colnum(self):\n",
    "        return {k: i for i, k in enumerate(self.columns)}\n",
    "\n",
    "    @property\n",
    "    def rowname_to_rownum(self):\n",
    "        return {k: i for i, k in enumerate(self.index)}\n",
    "    \n",
    "    def _compiled_qualifier(self, func_qualifier, mapper):\n",
    "        return hash(functools.reduce(lambda x, y: f'{x}&{y}', mapper) + func_qualifier)\n",
    "\n",
    "    def apply(self, func, axis = 0, *args, pandas_fallback = False, **kwargs):\n",
    "        if pandas_fallback: \n",
    "            logger.warning(f'{__class__} finish in pandas fallback for func {func}')\n",
    "            return super().apply(func, axis = 0, *args, **kwargs)\n",
    "        if args or kwargs:\n",
    "            logger.warning(f'{__class__} apply only supports func and axis arguments, using default pandas apply')\n",
    "            return super().apply(func, axis = 0, *args, **kwargs)\n",
    "        return pandopt((self._compiled_func.get((name:=self._compiled_qualifier(func_qualifier = func.__qualname__, mapper=(mapper:=self.colname_to_colnum if axis else self.rowname_to_rownum)))) or self._build_apply_versions(func, mapper, name))(self.to_numpy() if axis else self.to_numpy().T), index = self.index if axis else self.columns)\n",
    "\n",
    "    def _with_fallback_wrap(self, apply_func_dict):\n",
    "        def _with_protects(*args, **kwargs):\n",
    "            for key in ('_vectorized_nb_compyled', '_loop_compyled', '_vectorized', '_loop'):\n",
    "                if key not in apply_func_dict:\n",
    "                    continue\n",
    "                try:\n",
    "                    return apply_func_dict[key](*args, **kwargs)\n",
    "                except:\n",
    "                    apply_func_dict.pop(key)\n",
    "            return self.apply(*args, pandas_fallback = True, **kwargs)\n",
    "        return _with_protects\n",
    "    \n",
    "    def _build_apply_versions(self, func, map, name):\n",
    "        self._compiled_func[name] = self._with_fallback_wrap(_prepare_funcs(func, map))\n",
    "        return self._compiled_func[name]\n",
    "\n",
    "    def rolling(self, window, *args, **kwargs):\n",
    "        return pandoptRoll(self, window=window, *args, **kwargs)\n",
    "\n",
    "    \n",
    "    def groupby(self, *args, **kwargs):\n",
    "        return pandoptGroupBy(self, *args, **kwargs)\n",
    "\n",
    "    def resample(self, *args, **kwargs):\n",
    "        return pandoptResampler(self, *args, **kwargs)\n",
    "\n",
    "    def expanding(self, *args, **kwargs):\n",
    "        return pandoptExpanding(self, *args, **kwargs)\n",
    "\n",
    "\n",
    "    def _apply_with_compiled_func(self, func, data, axis=0, *args, **kwargs):\n",
    "        name = self._compiled_qualifier(func_qualifier=(func_name:=func.__qualname__), mapper=(mapper:=self.colname_to_colnum if axis else self.rowname_to_rownum))\n",
    "        compiled_func = self._compiled_func.get(name) or self._build_apply_versions(func, mapper, name)\n",
    "        return res.T if hasattr((res:=compiled_func(data, *args, **kwargs)), 'T') else res\n",
    "\n",
    "@make_class_decorator(autowrap_pandas_return)\n",
    "class pandoptRoll(pd.core.window.rolling.Rolling):\n",
    "    _outside_call = True\n",
    "    def __init__(self, df, *args, **kwargs):\n",
    "        self._idf = df\n",
    "        super().__init__(df, *args, **kwargs)\n",
    "\n",
    "    def agg(self, func, *args, **kwargs):\n",
    "        if isinstance(func, dict):\n",
    "            # For dictionary input, apply each function to the respective column\n",
    "            result = {}\n",
    "            for column, func_name in func.items():\n",
    "                if func_name in ['mean', 'std', 'sum', 'min', 'max', 'count', 'median']:\n",
    "                    result[column] = super().agg({column: func_name})\n",
    "                else:\n",
    "                    result[column] = self.apply(lambda x: x[column].pipe(func_name), *args, **kwargs)\n",
    "            return pandopt(result)\n",
    "        elif func in ['mean', 'std', 'sum', 'min', 'max', 'count', 'median']:\n",
    "            return super().agg(func, *args, **kwargs)\n",
    "        else:\n",
    "            return self.apply(func, *args, **kwargs)\n",
    "        \n",
    "    def apply(self, func, *args, pandas_fallback=False, **kwargs):\n",
    "        try:\n",
    "            return pandopt(self._idf._apply_with_compiled_func(func, sliding_window_view(df.to_numpy(), self.window, axis=0), axis=2, *args, **kwargs), columns=df.columns, index=df.index[self.window-1:])\n",
    "        except Exception as e:\n",
    "            logger.warning(f'Error in pandoptRoll apply: {e}')\n",
    "            if pandas_fallback:\n",
    "                return super().apply(func, *args, **kwargs)\n",
    "            raise\n",
    "            \n",
    "@make_class_decorator(autowrap_pandas_return)\n",
    "class pandoptGroupBy(pd.core.groupby.DataFrameGroupBy):\n",
    "    _outside_call = True\n",
    "    def __init__(self, df, *args, **kwargs):\n",
    "        self._idf = df\n",
    "        super().__init__(df, *args, **kwargs)\n",
    "\n",
    "    def agg(self, func, *args, **kwargs):\n",
    "        if isinstance(func, dict):\n",
    "            # For dictionary input, apply each function to the respective column\n",
    "            result = {}\n",
    "            for column, func_name in func.items():\n",
    "                if func_name in ['mean', 'std', 'sum', 'min', 'max', 'count', 'median']:\n",
    "                    result[column] = super().agg({column: func_name})\n",
    "                else:\n",
    "                    result[column] = self.apply(lambda x: x[column].pipe(func_name), *args, **kwargs)\n",
    "            return pandopt(result)\n",
    "        elif func in ['mean', 'std', 'sum', 'min', 'max', 'count', 'median']:\n",
    "            return super().agg(func, *args, **kwargs)\n",
    "        else:\n",
    "            return self.apply(func, *args, **kwargs)\n",
    "\n",
    "    def apply(self, func, *args, pandas_fallback=False, **kwargs):\n",
    "        try:\n",
    "            results = []\n",
    "            for name, group in self:\n",
    "                result_array = self._idf._apply_with_compiled_func(func, group.to_numpy(), axis=1, *args, **kwargs)\n",
    "                \n",
    "                # If the function returns a single value per group\n",
    "                if result_array.ndim == 1 or result_array.shape[1] == 1:\n",
    "                    result_df = pandopt(result_array, index=group.index, columns=[func.__name__])\n",
    "                else:\n",
    "                    result_df = pandopt(result_array, index=group.index, columns=group.columns)\n",
    "                \n",
    "                results.append(result_df)\n",
    "\n",
    "            return pd.concat(results, axis=0)\n",
    "        except Exception as e:\n",
    "            logger.warning(f'Error in pandoptGroupBy apply: {e}')\n",
    "            if pandas_fallback:\n",
    "                return super().apply(func, *args, **kwargs)\n",
    "            raise\n",
    "\n",
    "@make_class_decorator(autowrap_pandas_return)\n",
    "class pandoptResampler(pd.core.resample.Resampler):\n",
    "    _outside_call = True\n",
    "    def __init__(self, df, *args, **kwargs):\n",
    "        self._idf = df\n",
    "        super().__init__(df, *args, **kwargs)\n",
    "\n",
    "    def agg(self, func, *args, **kwargs):\n",
    "        if isinstance(func, dict):\n",
    "            results = {col: (super().agg({col: f}) if f in ['mean', 'std', 'sum', 'min', 'max', 'count', 'median'] else self.apply(lambda x: x[col].pipe(f), *args, **kwargs)) for col, f in func.items()}\n",
    "            return pandopt(results)\n",
    "        elif func in ['mean', 'std', 'sum', 'min', 'max', 'count', 'median']:\n",
    "            return super().agg(func, *args, **kwargs)\n",
    "        else:\n",
    "            return self.apply(func, *args, **kwargs)\n",
    "\n",
    "    def apply(self, func, *args, pandas_fallback=False, **kwargs):\n",
    "        try:\n",
    "            if pandas_fallback:\n",
    "                return super().apply(func, *args, **kwargs)\n",
    "            return self._idf._apply_with_compiled_func(func, self._idf.to_numpy(), *args, **kwargs)\n",
    "        except Exception as e:\n",
    "            logger.warning(f'Error in pandoptResampler apply: {e}')\n",
    "            return super().apply(func, *args, **kwargs)\n",
    "\n",
    "@make_class_decorator(autowrap_pandas_return)\n",
    "class pandoptExpanding(pd.core.window.expanding.Expanding):\n",
    "    _outside_call = True\n",
    "    def __init__(self, df, *args, **kwargs):\n",
    "        self._idf = df\n",
    "        super().__init__(df, *args, **kwargs)\n",
    "\n",
    "    def agg(self, func, *args, **kwargs):\n",
    "        if isinstance(func, dict):\n",
    "            results = {col: (super().agg({col: f}) if f in ['mean', 'std', 'sum', 'min', 'max', 'count', 'median'] else self.apply(lambda x: x[col].pipe(f), *args, **kwargs)) for col, f in func.items()}\n",
    "            return pandopt(results)\n",
    "        elif func in ['mean', 'std', 'sum', 'min', 'max', 'count', 'median']:\n",
    "            return super().agg(func, *args, **kwargs)\n",
    "        else:\n",
    "            return self.apply(func, *args, **kwargs)\n",
    "\n",
    "    def apply(self, func, *args, pandas_fallback=False, **kwargs):\n",
    "        try:\n",
    "            if pandas_fallback:\n",
    "                return super().apply(func, *args, **kwargs)\n",
    "            return self._idf._apply_with_compiled_func(func, self._idf.to_numpy(), *args, **kwargs)\n",
    "        except Exception as e:\n",
    "            logger.warning(f'Error in pandoptExpanding apply: {e}')\n",
    "            return super().apply(func, *args, **kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d548f20a-4bf3-48cd-9660-f28e123d1298",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data=np.random.randn(100000,4), columns = ['A', 'B', 'C', 'D']).astype(np.float32)\n",
    "df['E'] = df['A'] // df['C']\n",
    "dfx = pandopt(df)\n",
    "\n",
    "%time df.groupby('E').agg(Measssn)\n",
    "%time dfx.groupby('E').agg(Measssn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4629a511-46d9-40fa-8c9d-5acebf480508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Measssn(X):\n",
    "    return np.mean(X, axis = 0)\n",
    "\n",
    "def neow(X):\n",
    "    return np.mean(X)\n",
    "\n",
    "df=pd.DataFrame(data=np.random.randn(1000,4), columns = ['A', 'B', 'C', 'D']).astype(np.float32)\n",
    "dfx = pandopt(df)\n",
    "%time dfx.rolling(10).apply(Measssn)\n",
    "# dfx._compiled_func\n",
    "# dfx.rolling(10).mean()\n",
    "dfx['E'] = dfx['A'] // dfx['C']\n",
    "dfx.groupby('E').apply(neow), dfx.rolling(10).apply(Measssn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cd9919-fdba-45df-842b-612568482e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "sliding_window_view(df.to_numpy().T, 3, axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41e197b-92b7-4007-aefd-fda1edfa2016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MIMMEAN(x):\n",
    "    return np.std(x, axis = 0)\n",
    "\n",
    "df=pd.DataFrame(data=np.random.randn(100000000,4), columns = ['A', 'B', 'C', 'D']).astype(np.float32)\n",
    "dfx = pandopt(df)\n",
    "\n",
    "\n",
    "\n",
    "#%time a = df.rolling(10).apply(f)\n",
    "%time b = dfx.rolling(10).apply(MIMMEAN)\n",
    "%time c = dfx.rolling(10).std()\n",
    "\n",
    "\n",
    "\n",
    "a , b, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192a21d0-c83d-47f3-b9a8-de7b7157ebf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data=np.random.randn(1000000,4), columns = ['A', 'B', 'C', 'D']).astype(np.float32)\n",
    "dfx = pandopt(df)\n",
    "df.rolling(10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa639eeb-459a-4a2a-98db-8af4ab16fa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return np.mean(x)\n",
    "\n",
    "df=pd.DataFrame(data=np.random.randn(1000000,4), columns = ['A', 'B', 'C', 'D']).astype(np.float32)\n",
    "dfx = pandopt(df)\n",
    "dfx.rolling(10)\n",
    "\n",
    "%time df.rolling(10).mean()\n",
    "%time dfx.rolling(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740e0fab-57aa-4c72-8da7-c99ca30a91ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(df.rolling(10, center=True), pd.core.window.rolling.Rolling)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
